{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5b421b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# from models.stylegan2.model import Generator, Encoder_BL\n",
    "# from models.encoders.psp_encoders import GradualStyleEncoder\n",
    "from models.psp import pSp\n",
    "from criteria.vgg_loss import VGGLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c04ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import tensor2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90990ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e75e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2tensor(image):\n",
    "    image = torch.FloatTensor(image).permute(2,0,1).unsqueeze(0)/255.\n",
    "    return (image-0.5)/0.5\n",
    "\n",
    "def tensor2image(tensor):\n",
    "    tensor = tensor.clamp_(-1., 1.).detach().squeeze().permute(1,2,0).cpu().numpy()\n",
    "    return tensor*0.5 + 0.5\n",
    "\n",
    "def imshow(img, size=5, cmap='jet'):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f939ace",
   "metadata": {},
   "source": [
    "# Load Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200ee3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1024  # select from [256, 512, 1024]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0c6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_root = './images/'\n",
    "img_name = 'gl1_01.png'\n",
    "\n",
    "# img = transform(Image.open(f'{imgs_root}/{img_name}')).to(device)\n",
    "# input_image = tensor2im(img)\n",
    "ori_img = Image.open(f'{imgs_root}/{img_name}')\n",
    "imgs = transform(ori_img).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b989ed9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548ad70",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d852c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psp model\n",
    "model_path = '../pretrained_models/psp_ffhq_encode.pt'\n",
    "ckpt = torch.load(model_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d68025",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = ckpt['opts']\n",
    "\n",
    "opts['checkpoint_path'] = model_path\n",
    "\n",
    "if 'learn_in_w' not in opts:\n",
    "    opts['learn_in_w'] = False\n",
    "if 'output_size' not in opts:\n",
    "    opts['output_size'] = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca5afe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pSp from checkpoint: ../pretrained_models/psp_ffhq_encode.pt\n",
      "Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "net = pSp(Namespace(**opts))\n",
    "net.eval()\n",
    "net.cuda()\n",
    "print('Model successfully loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     imgOut, z0 = net(imgs, resize=True, randomize_noise=False, return_latents=True)\n",
    "\n",
    "# imgOut = imgOut.to('cpu')\n",
    "# torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a04c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z0 = net.encoder(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0689203",
   "metadata": {},
   "source": [
    "# Improve Latent Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb322c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74905b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = transform2(ori_img).unsqueeze(0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546eb8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_loss = VGGLoss(device)\n",
    "\n",
    "z = z0.detach().clone()\n",
    "\n",
    "z.requires_grad = True\n",
    "optimizer = torch.optim.Adam([z], lr=0.01)\n",
    "\n",
    "for step in range(iterations):\n",
    "    imgs_gen, _ = net.decoder([z], \n",
    "                           input_is_latent=True, \n",
    "                           # truncation=truncation,\n",
    "                           # truncation_latent=trunc, \n",
    "                           randomize_noise=False)\n",
    "    imgs_gen.to('cpu')\n",
    "    \n",
    "    z_hat = net.encoder(imgs_gen)\n",
    "    z_hat.to('cpu')\n",
    "    \n",
    "    loss = F.mse_loss(imgs_gen, imgs) + vgg_loss(imgs_gen, imgs) + F.mse_loss(z0, z_hat)*2.0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "    if (step+1)%5 == 0:\n",
    "        print(f'step:{step+1}, loss:{loss.item()}')\n",
    "        imgs_fakes = torch.cat([img_gen for img_gen in imgs_gen], dim=1)        \n",
    "        imshow(tensor2image(torch.cat([imgs_real, imgs_fakes], dim=2)),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118b140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac90cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c32381",
   "metadata": {},
   "source": [
    "# Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650e2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output_image = tensor2im(imgOut)\n",
    "# res = np.concatenate([np.array(input_image.resize((256, 256))),\n",
    "#                     np.array(output_image.resize((256, 256)))], axis=1)\n",
    "# Image.fromarray(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
